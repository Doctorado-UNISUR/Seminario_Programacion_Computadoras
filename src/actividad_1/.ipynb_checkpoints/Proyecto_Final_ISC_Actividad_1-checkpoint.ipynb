{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b98d1ca8",
   "metadata": {},
   "source": [
    "# Proyecto de evaluación Actividad 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d703c9",
   "metadata": {},
   "source": [
    "**Estudiante**: Juan Carlos González Ibarra\n",
    "\n",
    "**Correo**: jcarlos0284@gmail.com\n",
    "\n",
    "**Fecha**: 17 de mayo, 2024\n",
    "\n",
    "**Contenido**\n",
    "- Tema\n",
    "- Planteamiento del problema\n",
    "- Objetivos\n",
    "- Metodología de Desarrollo\n",
    "- Extracción de Datos\n",
    "- Fuentes de extracción de datos \n",
    "- Que es la extracción de datos \n",
    "- Extracción de datos con Python\n",
    "- Data Clean\n",
    "- Almacenamiento base de datos\n",
    "- Algoritmos de Aprendizaje Supervisado y No Supervisado\n",
    "- Modelado de Datos\n",
    "- Análisis exploratorio de Datos (AED)\n",
    "- Resultados de AED\n",
    "- Visualización de datos\n",
    "- Conclusión\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ef0f05",
   "metadata": {},
   "source": [
    "## 1. Tema\n",
    "### 1.1 Planteamiento del problema\n",
    "La industria de los videojuegos ha experimentado un crecimiento significativo, impulsado por la popularidad de los videojuegos como formas de entretenimiento digital y el aumento en el número de jugadores. Sin embargo, este crecimiento presenta desafíos importantes. La constante evolución de los videojuegos, impulsada por avances tecnológicos y cambios en los hábitos de consumo, ha creado incertidumbre sobre cómo anticipar y adaptarse a las demandas cambiantes del mercado.\n",
    "Además, el lapso de la pandemia y las medidas de confinamiento incremento esta tendencia, con un aumento notable en el número de jugadores que utilizan plataformas como Nintendo, Xbox y Playstation. Este cambio en el comportamiento de los consumidores ha llevado a un aumento del 6,3% en el número de usuarios de consolas digitales en Estados Unidos. La proliferación de smartphones y el desarrollo de tecnologías como la realidad virtual han ampliado aún más el acceso a los videojuegos, atrayendo a una nueva generación de jugadores.\n",
    "En este contexto de intensa competitividad y demanda creciente de innovación, las empresas del sector enfrentan el desafío de mantenerse al día con las expectativas del público y encontrar formas innovadoras de ofrecer experiencias de juego únicas y atractivas. La idea del “metaverso” surge como una posible solución, ofreciendo un mundo virtual en el que los usuarios pueden crear y compartir sus propias experiencias. \n",
    "\n",
    "Por lo anterior, el proyecto plantea desarrollar una herramienta de predicción que pueda identificar con precisión qué estilos de videojuegos tienen el potencial de éxito.\n",
    "\n",
    "### 1.2 Objetivos\n",
    "\n",
    "•\tPlantear un método de desarrollo para la extracción, limpieza, almacenamiento y análisis de datos de videojuegos exitosos y no exitosos, considerando variables como género, plataforma de lanzamiento, reseñas de usuarios, ventas, entre otros.\n",
    "\n",
    "•\tDiseñar un modelo predictivo basado en machine learning que pueda predecir el potencial de éxito de un videojuego en función de sus características específicas.\n",
    "\n",
    "•\tEvaluar la eficacia del modelo de predicción mediante la comparación de las predicciones con el desempeño real de los videojuegos.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5701f52",
   "metadata": {},
   "source": [
    "## 2. Metodología de Desarrollo\n",
    "\n",
    "Para realizar el proyecto se desarrollarán módulos de código para cada uno de los puntos planteados en los objetivos para que se pueda permitir establecer las variables del tipo de Genero y/o Plataforma del Videojuego a desarrollar y poder determinar (experimentalmente) la predicción de ventas de ese videojuego tomando como referencia la variable copia de ventas del videojuego, así que, se va trabajar cada tarea de la siguiente forma:\n",
    "\n",
    "- Investigar las fuentes donde se puede obtener los datos para el proyecto.\n",
    "- Extraer los datos vía Web Scraping\n",
    "- Data Clean:\n",
    "    - Carga de Datos\n",
    "    - Preprocesar los datos.\n",
    "    - Eliminar variables irrelevantes.\n",
    "    - Imputar valores faltantes.\n",
    "    - Limpiar los nombres de los atributos que no se vayan a utilizar.\n",
    "\n",
    "- Almacenar los datos en un sistema de base de datos\n",
    "- Definición de la(s) Variable(s) Objetivo(s).\n",
    "- Generar un Modelo Predictivo Supervisado con Algoritmo de:\n",
    "\n",
    "    - Regresión: Este algoritmo puede predecir un valor continuo (como las ventas globales de un videojuego). Se trata de encontrar una relación entre las variables de entrada y la variable de salida que puede ser representada como una ecuación matemática. Los algoritmos de regresión son: regresión lineal, la regresión polinomial y la regresión de árbol de decisión.\n",
    "\n",
    "    - Clasificación: Este algoritmo puede predecir una categoría o clase (como el género de un videojuego). Se trata de encontrar una frontera de decisión que separe las diferentes clases en el espacio de las variables de entrada. Los algoritmos de clasificación son: regresión logística, los árboles de decisión, las máquinas de vectores de soporte y las redes neuronales.\n",
    "\n",
    "    - Predicción: Este algoritmo se utiliza para predecir. La diferencia radica en el tipo de variable de salida que se trata de predecir.\n",
    "\n",
    "- Evaluar el modelo.\n",
    "- Implementar el modelo.\n",
    "- Realizar un Análisis Exploratorio de los Datos para entender la distribución de las variables para conseguir el objetivo del proyecto:\n",
    "\n",
    "    - Análisis de Correlación de Ventas Globales por Consola y Genero.\n",
    "    - Análisis de Ventas Globales de Videojuegos por Plataforma.\n",
    "    - Análisis de Ventas Globales por Género.\n",
    "    - Análisis de Ventas Globales por Compañía de Desarrollo.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8a453e",
   "metadata": {},
   "source": [
    "## 3. Extracción de datos.\n",
    "### 3.1 Fuentes de extracción de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01325d5d",
   "metadata": {},
   "source": [
    "En este proyecto se cuenta con un conjunto de datos obtenidos a través de Web Scraping de las páginas web:\n",
    "- https://www.mobygames.com\n",
    "- https://www.kaggle.com/datasets/sidtwr/videogames-sales-dataset\n",
    "- https://www.kaggle.com/datasets/gregorut/videogamesales\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c3b484",
   "metadata": {},
   "source": [
    "### 3.2 Que es la extracción de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b789090d",
   "metadata": {},
   "source": [
    "La extracción de datos es un proceso crucial para cualquier organización que desee aprovechar al máximo su información para la toma de decisiones. Permite recuperar datos de diversas fuentes y transformarlos en un formato utilizable para su posterior análisis o almacenamiento. Los datos pueden provenir de bases de datos, hojas de cálculo, sitios web, archivos PDF, correos electrónicos, entre otros.\n",
    "\n",
    "La extracción de datos se puede utilizar para descubrir patrones o relaciones ocultas dentro de los datos para tomar decisiones informadas o crear modelos predictivos.\n",
    "\n",
    "La metodología de la extracción de datos implica los siguientes pasos:\n",
    "\n",
    "- Identificación de fuentes de datos: Determinar de dónde provienen los datos necesarios y qué método utilizar para cada fuente, como consultas SQL, APIs o software de web scrapping.\n",
    "\n",
    "- Establecimiento de conexiones: Establecer conexiones con las fuentes de datos seleccionadas utilizando métodos específicos según el tipo de fuente.\n",
    "\n",
    "- Consulta o recuperación de datos: Recuperar datos específicos utilizando consultas SQL, extracción de texto mediante OCR u otras técnicas según sea necesario.\n",
    "\n",
    "- Transformación y carga de datos: Transformar los datos extraídos para cumplir con el formato requerido, incluyendo la limpieza de datos, la normalización y el enriquecimiento, y guardarlos en un destino, como archivos planos o bases de datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469f3ac6",
   "metadata": {},
   "source": [
    "Para este paso se utilizará la técnica de web scraping con el lenguaje de programación Python versión 3.\n",
    "El web scraping es una técnica utilizada para extraer datos de sitios web de manera automatizada. Permite recopilar información de páginas web de forma sistemática, convirtiendo los datos no estructurados en un formato estructurado y utilizable. \n",
    "\n",
    "Para realizar web scraping en Python, hay varias bibliotecas útiles disponibles son:\n",
    "\n",
    "- **Beautiful Soup**: Es una biblioteca Python que se utiliza para extraer datos de archivos HTML y XML. Proporciona métodos simples para navegar y buscar en el árbol de análisis, lo que la hace muy útil para la extracción de datos de páginas web.\n",
    "\n",
    "- **Requests**: Aunque no es específicamente una biblioteca de web scraping, Requests es una biblioteca HTTP para Python que permite realizar solicitudes HTTP de manera sencilla. Es muy útil para descargar el contenido HTML de una página web antes de aplicar técnicas de web scraping con Beautiful Soup.\n",
    "\n",
    "- **Selenium**: Es una herramienta poderosa para automatizar navegadores web. Puede ser útil para interactuar con páginas web que requieren JavaScript para cargar o realizar acciones dinámicas. Selenium puede controlar un navegador web y simular la interacción del usuario.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8a894f",
   "metadata": {},
   "source": [
    "### 3.3 Extracción de datos con Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012336b2",
   "metadata": {},
   "source": [
    "#### 1. Para utilizar estas bibliotecas se ejecutarán los siguientes comandos para instalarlos en el entorno del lenguaje Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78feb961-dd8d-43a9-b858-bde59f9db1fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\programdata\\anaconda3\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: html5lib in c:\\users\\jc\\appdata\\roaming\\python\\python311\\site-packages (1.1)\n",
      "Requirement already satisfied: six>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from html5lib) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\programdata\\anaconda3\\lib\\site-packages (from html5lib) (0.5.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\programdata\\anaconda3\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\programdata\\anaconda3\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2024.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\programdata\\anaconda3\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\jc\\appdata\\roaming\\python\\python311\\site-packages (4.20.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\jc\\appdata\\roaming\\python\\python311\\site-packages (from selenium) (0.25.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\jc\\appdata\\roaming\\python\\python311\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\jc\\appdata\\roaming\\python\\python311\\site-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\jc\\appdata\\roaming\\python\\python311\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\jc\\appdata\\roaming\\python\\python311\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\jc\\appdata\\roaming\\python\\python311\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\jc\\appdata\\roaming\\python\\python311\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\jc\\appdata\\roaming\\python\\python311\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\programdata\\anaconda3\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install html5lib\n",
    "!pip install beautifulsoup4\n",
    "!pip install requests\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b71871",
   "metadata": {},
   "source": [
    "#### 2. Declarar las librerías "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cef11d81-2d68-469d-92c3-8d7761431ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ee5b05",
   "metadata": {},
   "source": [
    "#### 3. Se crea un dataframe para almacenar la información que se extraiga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6ce0444",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear un DataFrame vacío para almacenar los datos\n",
    "all_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602d7a60",
   "metadata": {},
   "source": [
    "#### 4. Se define el tipo de driver de web browser que se utilizara para obtener la información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae2f6cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especifique la ubicación del driver de Firefox\n",
    "driver = webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd0b7ad",
   "metadata": {},
   "source": [
    "#### 5. Se crea un bucle que iterara a través del rango de números de página para extraer datos del sitio web MobyGames. Para cada número de página en el rango especificado, el código construye una URL correspondiente a esa página, realiza una solicitud GET al sitio web utilizando Selenium, espera a que el JavaScript genere la tabla de datos, parsea el contenido HTML de la página utilizando BeautifulSoup, busca la tabla que contiene los datos, y luego se guarda en el DataFrame de Pandas **all_data** a partir de esta tabla. Una vez que itera a través de todas las páginas, cierra el driver de Selenium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3b32133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar a través de un rango de números de página\n",
    "# Supongamos que hay 10 páginas\n",
    "for i in range(1, 30):\n",
    "    # Construir la URL para la página actual\n",
    "    url = f\"https://www.mobygames.com/game/sort:moby_score/page:{i}/\"\n",
    "\n",
    "    # Hacer una petición GET al sitio web\n",
    "    driver.get(url)\n",
    "\n",
    "    # Espera que el JavaScript genere la tabla (puede que necesites ajustar el tiempo de espera)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Parsear el contenido de la página con BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "\n",
    "    # Buscar la tabla en el contenido de la página\n",
    "    table = soup.find('table')\n",
    "\n",
    "    # Crear un DataFrame de Pandas a partir de la tabla\n",
    "    df = pd.read_html(str(table))[0]\n",
    "\n",
    "    # Agregar los datos al DataFrame total\n",
    "    all_data = pd.concat([all_data, df])\n",
    "\n",
    "# Cerrar el driver de Selenium\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c26482",
   "metadata": {},
   "source": [
    "#### 6. Visualizar los datos que contiene el Data Frame **all_data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ab772fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    0    1     2  \\\n",
      "0                                   Baldur's Gate III  9.5  2020   \n",
      "1                                 Super Mario Odyssey  9.5  2017   \n",
      "2                                    Persona 5: Royal  9.3  2019   \n",
      "3           The Legend of Zelda: Tears of the Kingdom  9.3  2023   \n",
      "4             The Legend of Zelda: Breath of the Wild  9.3  2017   \n",
      "..                                                ...  ...   ...   \n",
      "13                                           Sonic CD  8.5  2011   \n",
      "14  Dragon Quest XI S: Echoes of an Elusive Age - ...  8.5  2019   \n",
      "15                                Fight Night Round 4  8.5  2009   \n",
      "16                                   Age of Mythology  8.5  2002   \n",
      "17                     The Elder Scrolls IV: Oblivion  8.5  2006   \n",
      "\n",
      "                               3  \n",
      "0              Larian Studios NV  \n",
      "1                   Nintendo EPD  \n",
      "2                Atlus Co., Ltd.  \n",
      "3                   Nintendo EPD  \n",
      "4                   Nintendo EPD  \n",
      "..                           ...  \n",
      "13         SEGA Enterprises Ltd.  \n",
      "14         Square Enix Co., Ltd.  \n",
      "15        Electronic Arts Canada  \n",
      "16  Ensemble Studios Corporation  \n",
      "17         Bethesda Game Studios  \n",
      "\n",
      "[522 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8c9896",
   "metadata": {},
   "source": [
    "#### 7. Se guardan los datos que contiene el Data Frame all_data en un archivo con extensión csv llamado \"consolas.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55714680",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv('consolas.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657d824a",
   "metadata": {},
   "source": [
    "#### 8. Se realiza este mismo proceso con las otras páginas que están como fuentes para tener más de un banco de datos que pueda ayudar a realizar la herramienta de predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d855832",
   "metadata": {},
   "source": [
    "Se tiene como resultados los archivos csv: \n",
    "  \n",
    "- 'juegos_mas_vendidos.csv'\n",
    "- 'consolas.csv'\n",
    "- 'consolas2.csv'\n",
    "- 'moby_score.csv'\n",
    "- 'vgsales.csv'\n",
    "- 'video_games.csv\n",
    "    \n",
    "estos archivos contienen diferente información que llevara a cabo el proceso **Data Clean** para eliminar, normalizar y posterior guardar los datos con las variables necesarias para el análisis exploratorio de los datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
